# -*- coding: utf-8 -*-
"""challenge_telecomx_parte2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-2X8UssX-PKvIsntDPbp7B4YAtVynVy2

#üõ†Ô∏è Prepara√ß√£o dos Dados

### Importa√ß√£o dos dados
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report


df = pd.read_csv('/content/dados_tratados.csv')
df.head()

"""### Remo√ß√£o de colunas irrelevantes"""

colunas_para_remover = ['customerID', 'gender', 'MultipleLines']
df_filtrado = df.drop(columns=colunas_para_remover)

print("\nPrimeiras 5 linhas do dataset filtrado:")
df_filtrado.head()

"""### Encoding"""

colunas_categoricas = df_filtrado.select_dtypes(include='object').columns.tolist()
df_encoded = pd.get_dummies(df_filtrado, columns=colunas_categoricas, drop_first=True)

print("Primeiras 5 linhas do dataset ap√≥s a codifica√ß√£o:")
df_encoded.head()

"""### Verifica√ß√£o da Propor√ß√£o de Evas√£oVerifica√ß√£o da Propor√ß√£o de Evas√£o"""

# Calcula a contagem de clientes que evadiram (Churn=1) e que permaneceram (Churn=0)
churn_counts = df_encoded['Churn_Yes'].value_counts()
print("Contagem de clientes por classe (Churn):")
print(churn_counts)
print("\n" + "="*50 + "\n")

# Calcula a propor√ß√£o de cada classe
total_clientes = churn_counts.sum()
proporcao_churn_nao = (churn_counts[0] / total_clientes) * 100
proporcao_churn_sim = (churn_counts[1] / total_clientes) * 100

plt.figure(figsize=(10, 7))

churn_counts.plot(kind='bar', color=['skyblue', 'salmon'])

plt.title('Distribui√ß√£o de Clientes por Status de Evas√£o (Churn)', fontsize=16)
plt.xlabel('Status de Evas√£o (Churn)', fontsize=12)
plt.ylabel('N√∫mero de Clientes', fontsize=12)
plt.ylim(0, churn_counts.max() * 1.4)
plt.xticks(ticks=[0, 1], labels=['N√£o Evadiram', 'Evadiram'], rotation=0, fontsize=11)

total_clientes = churn_counts.sum()
for index, value in enumerate(churn_counts):
    plt.text(index, value + 100, f'{value}\n({(value/total_clientes)*100:.2f}%)', ha='center', fontsize=11, fontweight='bold')

plt.show()

"""#üéØ Correla√ß√£o e Sele√ß√£o de *Vari√°veis*

### Visualizando a Matriz de Correla√ß√£o
"""

# Removendo a coluna 'Churn_Label' antes de calcular a matriz de correla√ß√£o, pois ela cont√©m strings.
df_numeric = df_encoded
correlation_matrix = df_numeric.corr()
correlation_with_churn = correlation_matrix['Churn_Yes']

top_correlated_features = correlation_with_churn[abs(correlation_with_churn) > 0.1].index.tolist()
top_correlated_matrix = df_numeric[top_correlated_features].corr()

plt.figure(figsize=(18, 15))
sns.heatmap(correlation_matrix,
            annot=True,
            cmap='coolwarm',
            fmt=".2f",
            linewidths=.5,
            annot_kws={"size": 10})
plt.title('Matriz de Correla√ß√£o das Vari√°veis', fontsize=16)
plt.show()

"""Essa matriz de correla√ß√£o mostra o quanto cada vari√°vel se relaciona linearmente com as outras, variando de **-1** (correla√ß√£o negativa perfeita) at√© **+1** (correla√ß√£o positiva perfeita). Aqui v√£o alguns pontos que saltam aos olhos:

---

## üîç **Principais observa√ß√µes**

1. **Churn\_Yes**

   * Correla√ß√£o **positiva** moderada com `InternetService_Fiber optic` (\~0.31), sugerindo que clientes com fibra √≥ptica t√™m maior tend√™ncia de evas√£o.
   * Correla√ß√£o **negativa** forte com `tenure` (\~-0.35): clientes que ficam h√° mais tempo tendem a n√£o evadir.
   * Correla√ß√£o **positiva** com `MonthlyCharges` (\~0.19): mensalidades mais altas podem estar associadas a mais churn.

2. **Tenure (tempo de perman√™ncia)**

   * Correla√ß√£o forte e **positiva** com `TotalCharges` (\~0.83) ‚Äî esperado, j√° que quanto mais tempo o cliente permanece, mais ele paga no total.
   * Correla√ß√£o **negativa** forte com vari√°veis de ‚ÄúNo internet service‚Äù (\~-0.76) ‚Äî provavelmente clientes sem internet s√£o mais antigos ou de planos antigos.

3. **MonthlyCharges**

   * Correla√ß√£o **positiva** forte com `InternetService_Fiber optic` (\~0.79) ‚Äî fibra tende a ser mais cara.
   * Correla√ß√£o **negativa** moderada com vari√°veis ‚ÄúNo internet service‚Äù (\~-0.66 a -0.76).

4. **Agrupamentos de servi√ßos**

   * V√°rias vari√°veis como `OnlineSecurity_Yes`, `OnlineBackup_Yes`, `TechSupport_Yes` t√™m **correla√ß√µes positivas** entre si (\~0.3), sugerindo que clientes que contratam um servi√ßo adicional tendem a contratar outros.

5. **Contratos**

   * `Contract_Two year` tem correla√ß√£o **negativa** forte com Churn (\~-0.3) ‚Äî contratos longos reduzem evas√£o.
   * `Contract_Month-to-month` (n√£o est√° diretamente no gr√°fico, mas inferida pelo ‚ÄúN√£o dois anos‚Äù e ‚ÄúN√£o um ano‚Äù) provavelmente tem correla√ß√£o positiva com churn.

---

## üìå **Interpreta√ß√£o pr√°tica**

* Clientes **antigos** e com **contratos mais longos** s√£o menos propensos a evadir.
* Clientes com **fibra √≥ptica** e **mensalidade alta** est√£o mais associados √† evas√£o ‚Äî talvez por quest√µes de custo ou expectativa de qualidade.
* Servi√ßos adicionais andam juntos: quem contrata um, costuma contratar v√°rios.

---

Se voc√™ quiser, posso gerar um **resumo s√≥ das correla√ß√µes mais fortes com Churn** e explicar como cada uma pode ser usada para previs√£o. Isso deixaria a an√°lise bem focada no que interessa para entender a evas√£o. Quer que eu fa√ßa?

### An√°lises Direcionadas

###Gr√°fico 1: Boxplot - Tempo de Contrato (tenure) vs. Evas√£o
"""

df_visualizacao = df_encoded.copy()
df_visualizacao['Churn_Label'] = df_visualizacao['Churn_Yes'].apply(lambda x: 'Evadiu' if x == True else 'N√£o Evadiu')


plt.figure(figsize=(10, 6))
sns.boxplot(x='Churn_Label', y='tenure', data=df_visualizacao, palette='Set2')
plt.title('Tempo de Contrato (meses) vs. Evas√£o de Clientes', fontsize=16)
plt.xlabel('Status de Evas√£o', fontsize=12)
plt.ylabel('Tempo de Contrato (meses)', fontsize=12)
plt.show()

"""O boxplot mostra que clientes que n√£o evadiram t√™m, em m√©dia, um tempo de contrato (tenure) muito maior do que os que evadiram.
Isso refor√ßa a correla√ß√£o negativa entre tempo de perman√™ncia e churn: quanto mais tempo o cliente est√° na empresa, menor a probabilidade de cancelar.

### Total Gasto (TotalCharges) vs. Evas√£o
"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='Churn_Label', y='Charges.Total', data=df_visualizacao, palette='coolwarm')
plt.title('Total Gasto vs. Evas√£o de Clientes', fontsize=16)
plt.xlabel('Status de Evas√£o', fontsize=12)
plt.ylabel('Total Gasto', fontsize=12)
plt.show()

"""O boxplot mostra que clientes que **n√£o evadiram** t√™m valores de **TotalCharges** significativamente mais altos, indicando que permaneceram mais tempo e gastaram mais com a empresa. Isso refor√ßa a correla√ß√£o negativa: quanto maior o gasto acumulado, menor a probabilidade de churn.

ü§ñ Modelagem Preditiva

###Separa√ß√£o de Dados
"""

X = df_encoded.drop('Churn_Yes', axis=1)
y = df_encoded['Churn_Yes']

# Dividir o dataset em conjuntos de treino e teste (80/20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Shape do conjunto de treino (X_train): {X_train.shape}")
print(f"Shape do conjunto de teste (X_test): {X_test.shape}")

"""### Modelo de Regress√£o Log√≠stica (com Padroniza√ß√£o)

Justificativa: A Regress√£o Log√≠stica √© um modelo linear que funciona bem para problemas de classifica√ß√£o bin√°ria. No entanto, sua performance √© muito afetada pela escala das vari√°veis. Por isso, a padroniza√ß√£o √© um passo crucial para garantir que todas as vari√°veis (tenure, MonthlyCharges, TotalCharges) tenham a mesma import√¢ncia no modelo
"""

# Criando e treinando o modelo
model_lr = LogisticRegression(random_state=42)
model_lr.fit(X_train_scaled, y_train)

# ‚û°Ô∏è Previs√µes no conjunto de teste e avalia√ß√£o
y_pred_lr = model_lr.predict(X_test_scaled)
acuracia_lr = accuracy_score(y_test, y_pred_lr)
cm_lr = confusion_matrix(y_test, y_pred_lr)

print("‚úÖ Avalia√ß√£o do Modelo de Regress√£o Log√≠stica")
print(f"Acur√°cia: {acuracia_lr:.2f}\n")
print("Relat√≥rio de Classifica√ß√£o:\n", classification_report(y_test, y_pred_lr))

# Gerando o gr√°fico da matriz de confus√£o
plt.figure(figsize=(8, 6))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['N√£o Evadiu', 'Evadiu'], yticklabels=['N√£o Evadiu', 'Evadiu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o - Regress√£o Log√≠stica', fontsize=14)
plt.show()

"""### Modelo Random Forest (sem Padroniza√ß√£o)


Justificativa: O Random Forest √© um modelo de ensemble baseado em √°rvores de decis√£o. Ao contr√°rio da Regress√£o Log√≠stica, ele n√£o √© sens√≠vel √† escala das vari√°veis, o que o torna ideal para ser treinado diretamente com os dados originais (n√£o padronizados). √â um modelo robusto e geralmente apresenta alta precis√£o.
"""

# Criando e treinando o modelo
model_rf = RandomForestClassifier(n_estimators=100, random_state=42)
model_rf.fit(X_train, y_train)

# ‚û°Ô∏è Previs√µes no conjunto de teste e avalia√ß√£o
y_pred_rf = model_rf.predict(X_test)
acuracia_rf = accuracy_score(y_test, y_pred_rf)
cm_rf = confusion_matrix(y_test, y_pred_rf)

print("‚úÖ Avalia√ß√£o do Modelo Random Forest")
print(f"Acur√°cia: {acuracia_rf:.2f}\n")
print("Relat√≥rio de Classifica√ß√£o:\n", classification_report(y_test, y_pred_rf))

# Gerando o gr√°fico da matriz de confus√£o
plt.figure(figsize=(8, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['N√£o Evadiu', 'Evadiu'], yticklabels=['N√£o Evadiu', 'Evadiu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o - Random Forest', fontsize=14)
plt.show()



"""### üìù An√°lise Cr√≠tica e Compara√ß√£o dos Modelos

Com base nos resultados t√≠picos de modelos de churn, aqui est√° uma an√°lise cr√≠tica das m√©tricas e da performance de cada um:

**1. Desempenho dos Modelos**

  * **Acur√°cia Geral:** Provavelmente, a **Acur√°cia** de ambos os modelos ser√° alta (acima de 75%), mas isso pode ser enganoso. Devido ao desequil√≠brio do *dataset* (muito mais clientes que n√£o evadiram), um modelo pode alcan√ßar alta acur√°cia simplesmente prevendo a classe majorit√°ria.
  * **Acur√°cia por Classe (Foco no `Churn`):**
      * **Regress√£o Log√≠stica:** Este modelo, por ser linear, provavelmente ter√° uma performance razo√°vel, mas pode ter dificuldade em capturar todas as nuances dos dados. Sua `Precis√£o` e `Recall` para a classe `Evadiu` (`1`) tendem a ser menores que as do Random Forest.
      * **Random Forest:** Por ser um modelo n√£o-linear e de *ensemble*, o **Random Forest** quase sempre superar√° a Regress√£o Log√≠stica. Ele √© mais capaz de identificar padr√µes complexos e, como resultado, ter√° um `Recall` mais alto para a classe `Evadiu` (conseguindo "capturar" mais clientes que realmente evadiram) e um `F1-score` superior.

**2. An√°lise de Overfitting e Underfitting**

  * **Regress√£o Log√≠stica:**

      * Este modelo √© naturalmente resistente ao **overfitting** devido √† sua simplicidade. √â mais prov√°vel que ele sofra de **underfitting**, ou seja, que seja "simples demais" para capturar todas as tend√™ncias complexas dos dados, especialmente se as rela√ß√µes entre as vari√°veis n√£o forem lineares. Isso se manifesta em uma performance de `Recall` e `F1-score` mediana para a classe `Evadiu`.

  * **Random Forest:**

      * O **Random Forest** √© um modelo mais poderoso e, portanto, tem um risco maior de **overfitting**. Para verificar se isso ocorreu, voc√™ precisaria comparar a performance do modelo nos dados de treino versus os dados de teste. Se a acur√°cia de treino for pr√≥xima de 100% e a de teste for significativamente menor, o *overfitting* √© um problema. Os par√¢metros `max_depth` ou `n_estimators` poderiam ser ajustados para mitigar isso.

**3. Qual Modelo Teve o Melhor Desempenho?**

  * **O Random Forest √©, na maioria das vezes, a melhor escolha.** Embora a acur√°cia geral possa ser similar, a capacidade do Random Forest de identificar corretamente os clientes que realmente v√£o evadir (`Recall` da classe `1`) ser√° superior. No contexto de neg√≥cios, identificar clientes em risco √© mais importante do que ter uma acur√°cia perfeita, j√° que a empresa pode tomar a√ß√µes para ret√™-los.

A matriz de confus√£o visualiza isso: o Random Forest provavelmente ter√° mais acertos na parte inferior direita ("Evadiu" previsto, "Evadiu" real) e menos erros na parte superior direita ("N√£o Evadiu" previsto, "Evadiu" real) do que a Regress√£o Log√≠stica.

###  üìùAn√°lise de Vari√°veis na Regress√£o Log√≠stica
A Regress√£o Log√≠stica utiliza coeficientes para determinar a import√¢ncia das vari√°veis. Um coeficiente positivo indica que o aumento no valor daquela vari√°vel aumenta a probabilidade de evas√£o. Um coeficiente negativo, por outro lado, diminui essa probabilidade. O valor absoluto do coeficiente indica o grau de impacto.
"""

# --- An√°lise dos Coeficientes ---
feature_names = X_train_scaled.columns
coeficientes = model_lr.coef_[0]

# Criar um DataFrame para visualiza√ß√£o
importancia_lr = pd.DataFrame({
    'Vari√°vel': feature_names,
    'Coeficiente': coeficientes
}).sort_values(by='Coeficiente', ascending=False)


# üìà Gerar o gr√°fico de barras
plt.figure(figsize=(12, 10))
sns.barplot(x='Coeficiente', y='Vari√°vel', data=importancia_lr, palette='coolwarm')
plt.title('Import√¢ncia das Vari√°veis (Regress√£o Log√≠stica)', fontsize=16)
plt.xlabel('Coeficiente (Impacto)', fontsize=12)
plt.ylabel('Vari√°vel', fontsize=12)
plt.show()

"""###  üìùAn√°lise de Vari√°veis no Random Forest
O Random Forest calcula a import√¢ncia das vari√°veis com base em como cada vari√°vel contribui para a redu√ß√£o da impureza (por exemplo, a impureza de Gini) durante as divis√µes das √°rvores. Uma pontua√ß√£o mais alta indica que a vari√°vel foi mais √∫til para a precis√£o do modelo.
"""

# --- An√°lise da Import√¢ncia das Vari√°veis ---
feature_importances = model_rf.feature_importances_
feature_names = X_train.columns

# Criar um DataFrame para visualiza√ß√£o
importancia_rf = pd.DataFrame({
    'Vari√°vel': feature_names,
    'Import√¢ncia': feature_importances
}).sort_values(by='Import√¢ncia', ascending=False)
# üìà Visualiza√ß√£o em gr√°fico de barras
plt.figure(figsize=(12, 8))
sns.barplot(x='Import√¢ncia', y='Vari√°vel', data=importancia_rf.head(15), palette='viridis')
plt.title('Top 15 Vari√°veis Mais Importantes (Random Forest)', fontsize=16)
plt.xlabel('Import√¢ncia Relativa', fontsize=12)
plt.ylabel('Vari√°vel', fontsize=12)
plt.show()

"""#An√°lise de Dados e Estrat√©gias para Reduzir a Evas√£o de Clientes üìä

Este relat√≥rio apresenta uma an√°lise detalhada dos principais fatores que influenciam a evas√£o de clientes (Churn). Com base na explora√ß√£o dos dados, identificamos padr√µes de comportamento e rela√ß√µes cruciais para entender por que os clientes cancelam. O objetivo √© traduzir esses insights em estrat√©gias de reten√ß√£o eficazes e acion√°veis.

  üîç Principais Fatores que Impulsionam a Evas√£o
A an√°lise mostrou que a decis√£o de cancelar o servi√ßo n√£o √© aleat√≥ria, mas est√° diretamente ligada a vari√°veis espec√≠ficas. Identificamos as seguintes como as mais influentes:

  - Tempo de Perman√™ncia (tenure): Clientes mais novos s√£o o grupo de maior risco. A taxa de evas√£o √© significativamente maior nos primeiros meses e diminui drasticamente com o tempo. üìâ

  - Contrato: O tipo de contrato √© o fator mais cr√≠tico para a reten√ß√£o. Clientes com contratos de 2 anos t√™m a menor probabilidade de evadir, enquanto contratos mensais representam o maior risco. ‚úÖ

  - Servi√ßo de Internet: O servi√ßo de fibra √≥ptica tem uma forte correla√ß√£o com a evas√£o, indicando que clientes que usam esse servi√ßo s√£o mais propensos a cancelar. Isso pode sugerir problemas de insatisfa√ß√£o. üìà

  - M√©todo de Pagamento: O uso de cheque eletr√¥nico √© um forte indicador de risco de churn. Esse m√©todo pode ser um sinal de clientes menos engajados ou insatisfeitos com a experi√™ncia de pagamento. ‚ö†Ô∏è

  - Custo Mensal: Clientes com cobran√ßas mensais mais altas tendem a evadir. O pre√ßo √© um fator decisivo na decis√£o de perman√™ncia. üí∞

   üöÄ Estrat√©gias de Reten√ß√£o Propostas
Com base nos fatores identificados, propomos a√ß√µes proativas para reduzir o churn:

  1. Programa de Boas-Vindas e Engajamento Antecipado

    - Motiva√ß√£o: Clientes com baixo tenure s√£o os mais vulner√°veis.

    - A√ß√£o: Lan√ßar um programa de acompanhamento proativo nos primeiros 3 a 6 meses. O contato pode ser por email, SMS ou liga√ß√£o para garantir a satisfa√ß√£o, solucionar d√∫vidas e refor√ßar o valor dos servi√ßos.

  2. Incentivo √† Fideliza√ß√£o com Contratos de Longo Prazo

    - Motiva√ß√£o: A lealdade aumenta drasticamente com contratos de 1 ou 2 anos.

    - A√ß√£o: Oferecer pacotes exclusivos com descontos, b√¥nus ou benef√≠cios adicionais (como acesso a plataformas de streaming) para clientes que migrarem de planos mensais para contratos de longo prazo.

  3. Melhoria e Otimiza√ß√£o do Servi√ßo de Fibra √ìptica

   - Motiva√ß√£o: Clientes de fibra √≥ptica representam um grupo de alto risco.

   - A√ß√£o: Realizar pesquisas de satisfa√ß√£o e auditorias de qualidade para o servi√ßo de fibra √≥ptica. Otimizar a velocidade, estabilidade e o suporte t√©cnico para garantir a melhor experi√™ncia poss√≠vel.

  4. Incentivo a M√©todos de Pagamento mais Est√°veis

   - Motiva√ß√£o: O m√©todo de pagamento via cheque eletr√¥nico √© um indicador de churn.

   - A√ß√£o: Oferecer um b√¥nus ou pequeno desconto para clientes que trocarem seu m√©todo de pagamento para d√©bito autom√°tico ou cart√£o de cr√©dito. Investigar e otimizar a experi√™ncia do usu√°rio com o m√©todo de cheque eletr√¥nico.
"""

